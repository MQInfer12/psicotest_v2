{"id": "batch_req_67eb323f27448190b3aeb8f5413d889b", "custom_id": "request-1", "response": {"status_code": 400, "request_id": "ca93ab518442c1d529b9b865f639dc06", "body": {"error": {"message": "This model's maximum context length is 16385 tokens. However, you requested 16974 tokens (15974 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
{"id": "batch_req_67eb323f37708190acd3f7526e1c0485", "custom_id": "request-2", "response": {"status_code": 400, "request_id": "263992ba6a922f2908349df0e4b1c369", "body": {"error": {"message": "This model's maximum context length is 16385 tokens. However, your messages resulted in 16828 tokens. Please reduce the length of the messages.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}